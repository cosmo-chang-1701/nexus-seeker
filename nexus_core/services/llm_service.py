import os
import json
import logging
from openai import AsyncOpenAI
from pydantic import BaseModel, Field
from typing import Literal

from config import LLM_API_BASE, LLM_MODEL_NAME, API_KEY

logger = logging.getLogger(__name__)

# ==========================================
# âš™ï¸ LLM Inference Server é€£ç·šè¨­å®š
# ==========================================
client_args = {}

if API_KEY:
    client_args["api_key"] = API_KEY
if LLM_API_BASE:
    client_args["base_url"] = LLM_API_BASE
client = AsyncOpenAI(**client_args)

# ==========================================
# ğŸ“Š Pydantic Schema å®šç¾© (Structured Output)
# ==========================================
class RiskAssessment(BaseModel):
    decision: Literal["APPROVE", "VETO"] = Field(
        description="é¢¨æ§è£æ±ºçµæœï¼šAPPROVE (æ‰¹å‡†) æˆ– VETO (å¦æ±º)"
    )
    tags: list[str] = Field(
        description="èƒå– 2 åˆ° 3 å€‹æ¥µåº¦ç²¾ç°¡çš„é¢¨æ§é—œéµå­—æ¨™ç±¤ï¼Œä¾‹å¦‚ï¼š['å¸¸è¦é›œéŸ³', 'Long Gamma', 'ç„¡é»‘å¤©éµé¢¨éšª']"
    )
    reasoning: str = Field(
        description="ä¸€å¥è©±çš„çµ‚æ¥µé¢¨æ§çµè«– (è«‹æ§åˆ¶åœ¨ 30 å­—ä»¥å…§ï¼Œæ¥µåº¦å†·éœå®¢è§€)"
    )

async def evaluate_trade_risk(symbol: str, strategy: str, news_context: str, reddit_context: str) -> dict:
    """
    å‘¼å« LLM é€²è¡Œ NLP æ–°èæ¯’æ€§åˆ†æèˆ‡é¢¨æ§å¯©æŸ¥
    """
    system_prompt = """
    ## Role & Objective
    You are a Quant Hedge Fund CRO. Evaluate option proposals by cross-referencing official news and Reddit sentiment (titles + consensus scores) to prevent tail risks.

    ## Decision Logic
    1. **VETO (Reject)**:
       - **Black Swans**: Fraud, SEC probes, bankruptcy, or executive departures.
       - **Retail Mania**: High Reddit consensus scores indicating FOMO or Short Squeezes. Strictly VETO Seller strategies (STO/Short Gamma) due to explosive IV risk.
    2. **APPROVE (Pass)**:
       - **Market Noise**: Macro data, routine product news, analyst ratings.
       - **Buyer Strategies (BTO/Long Gamma)**: Can tolerate or benefit from high Reddit volatility.

    ## Output Constraints
    - Strictly follow the JSON schema.
    - `reasoning` MUST be in Traditional Chinese (ç¹é«”ä¸­æ–‡), max 50 words. Focus strictly on core risks.
    - Use Taiwan options terminology: Call = "è²·æ¬Š", Put = "è³£æ¬Š" (Never use èªè³¼/èªæ²½).
    """

    user_prompt = f"""
    ### Trade Proposal for Review
    - **Underlying**: {symbol}
    - **Strategy**: {strategy}
    ---

    - **Recent News**:
    {news_context}

    ---

    - **Reddit Context**:
    {reddit_context}
    ---

    **Instruction**: Perform a risk audit based on the CRO guidelines and return the adjudication in the required structural format.
    """

    try:
        response = await client.responses.parse(
            model=LLM_MODEL_NAME,
            instructions=system_prompt, 
            input=user_prompt,
            text_format=RiskAssessment
            # å‚™è¨»ï¼šè‹¥æ‚¨ä½¿ç”¨çš„ vLLM ç‰ˆæœ¬è¼ƒèˆŠï¼Œæœªå®Œæ•´æ”¯æ´æ–°ç‰ˆ API æˆ– json_schemaï¼Œ
            # å‰‡éœ€æ”¹ç”¨ vLLM ç‰¹æœ‰çš„ extra_body åƒæ•¸
        )
        
        result = response.output_parsed
        tags_str = " ".join([f"[{tag}]" for tag in result.tags])
        formatted_reasoning = f"ğŸ·ï¸ æ¨™ç±¤ï¼š{tags_str}\nğŸ“ ç†ç”±ï¼š{result.reasoning}"
        return {
            "decision": result.decision,
            "reasoning": formatted_reasoning
        }

    except Exception as e:
        logger.error(f"[{symbol}] LLM ä¼ºæœå™¨é€£ç·šæˆ–æ¨è«–å¤±æ•—: {e}")
        # Fail-Open ç­–ç•¥
        return {"decision": "APPROVE", "reasoning": f"AI ä¼ºæœå™¨é›¢ç·šæˆ–ç•°å¸¸ï¼Œé è¨­æ”¾è¡Œ: {str(e)}"}